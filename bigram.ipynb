{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8db4ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f111f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/home/scai/phd/aiz218323/scratch/Courses/nanoGPT/input.txt\"\n",
    "\n",
    "with open(data_file) as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbbbdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(file_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f746a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters : 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(list(set(file_content)))\n",
    "print(f\"Number of characters : {len(characters)}\")\n",
    "print(\"\".join(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32dd5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {c:i for i, c in enumerate(characters)}\n",
    "itos = {i:c for c, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "074115ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 8, 0, 4, 8, 0, 2, 1, 4, 8, 0, 6, 1, 1, 9, 8, 1, 4, 0, 5, 2, 8, 1,\n",
       "        8, 9, 7, 3, 1, 5, 5, 9, 9, 1, 7, 8, 4, 6, 7, 0, 8, 9, 7, 6, 6, 1, 8, 3,\n",
       "        5, 0, 4, 6, 8, 0, 3, 3, 6, 8, 4, 7, 9, 7, 5, 0, 2, 7, 9, 1, 1, 0, 6, 7,\n",
       "        4, 0, 6, 7, 0, 4, 8, 5, 7, 2, 8, 2, 8, 8, 4, 1, 0, 3, 9, 2, 9, 3, 1, 9,\n",
       "        8, 8, 6, 3, 4, 8, 3, 1, 1, 0, 0, 3, 6, 7, 2, 9, 6, 3, 0, 2, 3, 3, 6, 1,\n",
       "        7, 2, 8, 0, 3, 2, 0, 6, 9, 7, 0, 9, 7, 5, 8, 5, 6, 2, 9, 3, 6, 8, 0, 9,\n",
       "        5, 2, 7, 5, 9, 0, 8, 5, 7, 2, 1, 3, 2, 9, 4, 1, 1, 3, 6, 1, 5, 5, 3, 3,\n",
       "        3, 0, 5, 2, 0, 7, 3, 9, 3, 3, 4, 9, 1, 5, 1, 7, 8, 2, 3, 5, 4, 8, 2, 8,\n",
       "        1, 5, 3, 0, 9, 6, 5, 4, 0, 8, 2, 7, 4, 4, 9, 5, 1, 9, 8, 5, 1, 4, 0, 6,\n",
       "        5, 3, 1, 1, 6, 0, 9, 9, 9, 3, 3, 5, 2, 8, 2, 1, 3, 4, 4, 0, 8, 7, 9, 9,\n",
       "        2, 4, 8, 6, 2, 3, 0, 7, 9, 9, 6, 7, 7, 9, 3, 9, 2, 3, 1, 4, 4, 8, 6, 0,\n",
       "        5, 0, 2, 7, 9, 1, 0, 8, 7, 4, 0, 8, 3, 5, 4, 3, 2, 5, 9, 3, 4, 1, 1, 4,\n",
       "        1, 5, 0, 6, 9, 2, 6, 9, 2, 2, 1, 9, 7, 9, 8, 9, 0, 4, 0, 5, 4, 3, 4, 6,\n",
       "        6, 4, 5, 7, 5, 5, 6, 6, 3, 8, 2, 4, 6, 8, 1, 9, 5, 9, 0, 6, 6, 5, 8, 9,\n",
       "        5, 1, 8, 3, 2, 6, 7, 0, 9, 1, 3, 5, 0, 7, 7, 7, 6, 8, 9, 2, 5, 2, 8, 7,\n",
       "        7, 6, 8, 3, 7, 4, 3, 2, 6, 1, 7, 4, 8, 2, 2, 0, 0, 5, 4, 7, 7, 7, 7, 0,\n",
       "        0, 1, 6, 2, 4, 2, 3, 0, 4, 2, 4, 6, 9, 8, 9, 1, 7, 7, 2, 8, 1, 5, 0, 4,\n",
       "        4, 4, 7, 0, 7, 9, 4, 8, 4, 8, 2, 5, 7, 7, 4, 2, 1, 8, 4, 6, 1, 3, 5, 8,\n",
       "        9, 6, 1, 0, 0, 7, 5, 3, 1, 7, 8, 1, 2, 7, 3, 8, 7, 2, 9, 1, 9, 7, 0, 8,\n",
       "        8, 6, 6, 2, 6, 2, 5, 9, 2, 9, 5, 7, 9, 4, 5, 5, 2, 0, 8, 2, 2, 3, 6, 6,\n",
       "        2, 2, 7, 9, 4, 6, 4, 5, 4, 0, 1, 7, 8, 1, 2, 0, 8, 5, 6, 8, 8, 9, 5, 6,\n",
       "        1, 6, 9, 8, 0, 2, 0, 5, 3, 7, 1, 3, 5, 0, 3, 1, 4, 2, 5, 6, 1, 0, 1, 7,\n",
       "        9, 5, 5, 9, 8, 1, 6, 7, 2, 5, 6, 8, 3, 0, 2, 7, 5, 0, 4, 7, 3, 4, 0, 1,\n",
       "        7, 1, 8, 4, 2, 2, 6, 8, 5, 8, 4, 7, 7, 4, 5, 1, 3, 3, 3, 3, 3, 7, 9, 7,\n",
       "        9, 8, 3, 9, 4, 2, 1, 1, 4, 4, 8, 4, 4, 3, 4, 5, 7, 6, 7, 4, 3, 5, 1, 9,\n",
       "        4, 9, 4, 7, 6, 7, 4, 9, 2, 7, 1, 0, 0, 8, 0, 2, 7, 7, 7, 1, 8, 3, 0, 8,\n",
       "        9, 9, 4, 6, 5, 9, 0, 9, 1, 7, 8, 8, 7, 2, 1, 3, 6, 7, 4, 5, 5, 2, 1, 2,\n",
       "        8, 6, 1, 2, 1, 6, 3, 0, 4, 2, 9, 9, 9, 7, 9, 3, 2, 2, 9, 2, 2, 6, 1, 7,\n",
       "        6, 3, 2, 4, 1, 3, 2, 7, 6, 0, 1, 1, 6, 7, 0, 5, 3, 7, 0, 3, 0, 9, 4, 2,\n",
       "        6, 1, 9, 4, 6, 1, 2, 0, 2, 4, 8, 0, 0, 5, 1, 1, 0, 6, 6, 3, 1, 7, 1, 4,\n",
       "        0, 0, 1, 0, 7, 6, 6, 7, 3, 0, 1, 0, 1, 9, 7, 0, 2, 9, 4, 9, 5, 6, 4, 1,\n",
       "        7, 7, 5, 9, 9, 6, 4, 7, 7, 8, 6, 9, 9, 6, 1, 0, 9, 1, 6, 9, 9, 9, 1, 9,\n",
       "        2, 5, 8, 4, 5, 1, 0, 2, 7, 6, 9, 7, 0, 1, 9, 7, 1, 1, 3, 6, 3, 8, 9, 7,\n",
       "        4, 7, 9, 6, 2, 7, 6, 5, 6, 7, 8, 9, 2, 9, 2, 4, 2, 7, 5, 5, 6, 6, 0, 4,\n",
       "        4, 5, 5, 5, 4, 3, 4, 8, 0, 8, 3, 3, 6, 9, 8, 6, 9, 0, 1, 9, 1, 3, 6, 2,\n",
       "        6, 8, 1, 7, 3, 1, 0, 4, 8, 6, 3, 8, 5, 0, 0, 5, 1, 6, 9, 1, 9, 1, 0, 6,\n",
       "        0, 4, 5, 7, 7, 0, 9, 8, 0, 9, 3, 0, 3, 8, 3, 1, 0, 7, 9, 3, 9, 1, 6, 3,\n",
       "        8, 7, 5, 9, 1, 6, 9, 8, 7, 4, 1, 3, 7, 1, 2, 8, 7, 0, 0, 3, 0, 8, 1, 4,\n",
       "        7, 0, 8, 1, 6, 8, 8, 4, 2, 5, 5, 4, 9, 9, 8, 3, 0, 0, 4, 3, 5, 0, 6, 9,\n",
       "        4, 8, 8, 5, 8, 1, 1, 7, 6, 6, 8, 8, 8, 7, 0, 4, 9, 1, 4, 8, 5, 5, 4, 3,\n",
       "        5, 7, 6, 1, 7, 5, 1, 9, 4, 4, 0, 9, 2, 7, 9, 6, 9, 1, 6, 1, 4, 7, 5, 5,\n",
       "        7, 2, 0, 0, 6, 1, 5, 0, 1, 5, 2, 5, 0, 1, 9, 6])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "175582d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(block_size, batch_size):\n",
    "    idxs = torch.randint(len(file_content)-block_size, (batch_size,))\n",
    "    batch = torch.tensor([[stoi[c] for c in file_content[idx:idx+block_size+1]] for idx in idxs] , dtype=torch.long)\n",
    "    x = batch[:, :block_size]\n",
    "    y = batch[:, 1:block_size+1]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d8dc0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "x, y = get_batch(block_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ffa6770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2583b64",
   "metadata": {},
   "source": [
    "Language modelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a6b3ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58]) : 43\n",
      "tensor([58, 46]) : 51\n",
      "tensor([58, 46, 43]) : 1\n",
      "tensor([58, 46, 43, 51]) : 59\n",
      "tensor([58, 46, 43, 51,  1]) : 54\n",
      "tensor([58, 46, 43, 51,  1, 59]) : 6\n",
      "tensor([58, 46, 43, 51,  1, 59, 54]) : 0\n"
     ]
    }
   ],
   "source": [
    "block_x = x[0]\n",
    "block_y = y[0]\n",
    "\n",
    "for t in range(1, example.shape[0]):\n",
    "    print(f'{block_x[:t]} : {block_y[t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e65d2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.co_occurence_matrix = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        logits = model.co_occurence_matrix(x)\n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), y.contiguous().view(B*T))\n",
    "        return logits, loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, max_length):\n",
    "        s = \"\\n\"\n",
    "        for _ in range(max_length):\n",
    "            logit, _ = self.forward(torch.tensor(stoi[s[-1]]))\n",
    "            prob = F.softmax(logit, dim=0)\n",
    "            idx = torch.multinomial(prob, num_samples=1)[0].item()\n",
    "            s += itos[idx]\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b0e11122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(len(characters))\n",
    "logits, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f6f2ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vDqz'AtkxLFdlDqSIhFyZl,!JkOTJiIU-mHbwok;n3t;Rkd!?LnRAsdgxnuO\n",
      "BYTd;$tTv;rV'vATseVSxXX?cMMREr:q 3CijgLxpCTcM\n",
      "j?sTXX-TZ-N?$PjLtE\n",
      "r$vHb&k KbqMr.xoZoZ$ElsiC!qlV'fWKjxSSJGUfehfff?KfftLHEQ$LllioVSut'fuMtdk!q'CTiugnJ:XT,gUk;VD;H.xpehAlGDr$k NBYtKzC&?NCwygVDr,NjGQMmseV IuP?LFu e-ZyNVvS:vRMdUyJh&ks lfU,MLrE\n",
      "BGMzoVh$kONj!i'f,mFxOhctLr,-Qu 3mBfFkCLS:j&?WoiHngQ$OATu\n",
      "wRhkTh:fU:XM;DNcgl:fF xTHGDKbouYGX$kBCL;v-rD\n",
      "aSSo:i.xoO&hK$k IQJra;lIwthpVljsNcMYtcygdrpTvLrOUyA3$tAFDeMmG?:DjUP SjwBCFxSjQm,-yMIEU'Dmoq?VVVtLWvGOo ?xvBY;NaJ&mOcDS:Ds!XYQ.\n",
      "TfTuMzckxNj;aHT:NtRkmoRafwtMvUkOuc\n",
      ":SusA G?D;yJ$d?bowzWKxAV,-EeXwYyorLrU:HTzueSu,kCPRH$Lr!FZtk vq?'a ,ff;uKTbqkeSijMb-SVDqqeJHe'3TsA;FKcDsA;IhhxTddGI:DiBrLrcGS.NsNIuYy'iC'MbB3\n",
      "I$ytLrohKLO\n",
      "AF?N:BrLGkJhP,GSuzJU\n",
      "\n",
      ";UnH;RyAqJKNOw,UPhMvvy-DQ;MRfAjVqvATd-mGvd;UpeSC!\n",
      "EuM;Hs Ef?'!Nr3PRh.?MVIDTNs KNaWKpgdQoZimCIMbqb-LS-;AXSuwxSMeQhjf?Vn,.wksin-SpA\n",
      "GN;xAXd:jPYTboAKftkWKxPaM;fTA\n",
      "F.wli:KlePlzoRJu,'.hpV'nFSRHboZo 3XBY,AE3WqO&xlQCLPhLZYKBk DJSMHDsLEDQdEW?wq'wiq S$3e\n",
      "wkKlWVsjfTplruo:\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f6c1b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "637f4873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.2668299674987793\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iterations):\n",
    "    x, y = get_batch(block_size, batch_size)\n",
    "    logits, loss = model(x, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f'Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b985f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ORD:\n",
      "BForder mmand withavitohethinwinond cand w trth as?\n",
      "A M:\n",
      "thes e. t he pre blousther ing wak's f?\n",
      "CLoveas tslir; am.-wor an,\n",
      "\n",
      "Q!RAno\n",
      "ARYONowainove neu.\n",
      "Whemoust al an weis,\n",
      "ANo d os, illlend the:\n",
      "\n",
      "ARO:\n",
      "Bu meppiato anchans, kelo spef\n",
      "TINE:\n",
      "\n",
      "KEThousho avieves tt, arud faiocharnonghand ldar f Whaco flvatorst ma ofacay\n",
      "An wtur your, hthe.\n",
      "Therd tousalitin S:\n",
      "\n",
      "DQMInetoouise th co ilse ece oucheworcayoptheino s t.\n",
      "O:\n",
      "DYling ppiesa me.\n",
      "G gee ohen s ws o the me't y leles hosevesit Soreacheckfuiu.\n",
      "\n",
      "'d!\n",
      "DWe th h iawired't;\n",
      "Tonerind f-feo.\n",
      "Fiswd way,\n",
      "y ch,\n",
      "NOUMall!vend tt f bom iediprte n ceje nond t her and hatl msmatoo cir yof uthiggrt sprd ainseanow healent thinghetrievery u, st ce,\n",
      "Tin o-LEYo s ord celst theq-f wis FOFBurued it,\n",
      "\n",
      "YO:\n",
      "MKere IGOus t n mellllll de t, won! anthethericonowiverelicofosthe hldu mpellon Ifat\n",
      "WI he dsig s fam be, wardve sbordyo whican.\n",
      "'llst ll y he nourth d thanve hathis d t f ato prdng emiscund; Inckerestte bsty, wet se, fo buofo\n",
      "I g\n",
      "\n",
      "Thetick k mbil wnou?\n",
      "Wis a\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03358035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
